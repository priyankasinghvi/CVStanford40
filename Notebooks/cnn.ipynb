{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2, os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense, Activation, Dropout, MaxPool2D, AveragePooling2D, Conv2D, GlobalAvgPool2D, Flatten, BatchNormalization\n",
    "from keras.layers.advanced_activations import ReLU\n",
    "from keras.models import Model\n",
    "np.random.seed(1337) # for reproducibility\n",
    "from keras.optimizers import SGD\n",
    "#from layers import ShakeShake\n",
    "#from lr_callbacks import Step_decay, InternalStateHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_classes = 2\n",
    "nb_epoch = 30\n",
    "bn_axis = 3\n",
    "actionDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'applauding': 1, 'blowing_bubbles': 2, 'brushing_teeth': 3, 'cleaning_the_floor': 4, 'climbing': 5, 'cooking': 6, 'cutting_trees': 7, 'cutting_vegetables': 8, 'drinking': 9, 'feeding_a_horse': 10, 'fishing': 11, 'fixing_a_bike': 12, 'fixing_a_car': 13, 'gardening': 14, 'holding_an_umbrella': 15, 'jumping': 16, 'looking_through_a_microscope': 17, 'looking_through_a_telescope': 18, 'playing_guitar': 19, 'playing_violin': 20, 'pouring_liquid': 21, 'pushing_a_cart': 22, 'reading': 23, 'phoning': 24, 'riding_a_bike': 25, 'riding_a_horse': 26, 'rowing_a_boat': 27, 'running': 28, 'shooting_an_arrow': 29, 'smoking': 30, 'taking_photos': 31, 'texting_message': 32, 'throwing_frisby': 33, 'using_a_computer': 34, 'walking_the_dog': 35, 'washing_dishes': 36, 'watching_TV': 37, 'waving_hands': 38, 'writing_on_a_board': 39, 'writing_on_a_book': 40}\n"
     ]
    }
   ],
   "source": [
    "def create_dict_of_actions():\n",
    "    global actionDict\n",
    "    actionDict = {}\n",
    "    contents = []\n",
    "    file = open(\"actions.txt\", \"r\")\n",
    "    i = 1\n",
    "    if file.mode == 'r':\n",
    "        fl = file.readlines()\n",
    "        for f in fl:\n",
    "            f = f.rstrip(\"\\n\")\n",
    "            contents.append(f)\n",
    "            actionDict[f] = i\n",
    "            i += 1\n",
    "            \n",
    "        file.close()\n",
    "        \n",
    "create_dict_of_actions()\n",
    "#print(actionDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6520   3012\n"
     ]
    }
   ],
   "source": [
    "def paths_list_from_directory(directory):\n",
    "    \n",
    "    # Loading full image directories\n",
    "    subdirs = [[] for i in range(2)]\n",
    "    actions = [[] for i in range(40)]\n",
    "    \n",
    "    # Load all images\n",
    "    for (dirpath,dirname,filename) in os.walk(directory):\n",
    "        for file in filename:\n",
    "            index = 0\n",
    "            if file[:-8] in actionDict:\n",
    "                index = actionDict[file[:-8]] - 1\n",
    "            else: \n",
    "                continue\n",
    "            actions[index].append(os.path.join(dirpath,file))\n",
    "    \n",
    "    # To have equal number of images for training, get action class with lowest number of images\n",
    "    trainnum = 9999;\n",
    "    for l in actions:\n",
    "        if trainnum > len(l):\n",
    "            trainnum = len(l)\n",
    "    # Segment into training and testing 9:1\n",
    "    trainnum = int(0.9*trainnum)\n",
    "    \n",
    "    # Segment each action class into training and testing \n",
    "    # using a dynamic test size so that equal number of\n",
    "    # images are used per action for training\n",
    "    for l in actions:\n",
    "        test_size = (len(l) - trainnum) / len(l)\n",
    "        action_train, action_test = train_test_split(l, test_size = test_size)\n",
    "        subdirs[0].extend(action_train)\n",
    "        subdirs[1].extend(action_test)\n",
    "    #print(len(subdirs[0]),\" \",len(subdirs[1]))\n",
    "    return subdirs\n",
    "\n",
    "#paths = paths_list_from_directory('./JPEGImages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "\n",
    "\n",
    "    # [1] Get the file category and make the conversion. If 'dog' assign it integer 1, if 'cat' assign it integer 0.\n",
    "    # Default label = cat\n",
    "    label = 0\n",
    "    if len(filename) == 0 or (not isinstance(filename, str)):\n",
    "        # Error loading image\n",
    "        label = -1\n",
    "        return (None, -1)\n",
    "    if filename.find('Dog') != -1:\n",
    "        label = 1\n",
    "\n",
    "    # [2] Load the image in greyscale with opencv.\n",
    "    image = cv2.imread(filename,0)\n",
    "    # Check that image read was successful\n",
    "    if np.shape(image) != ():\n",
    "            \n",
    "        height, width = image.shape[:2]\n",
    "        crop_dim = None\n",
    "        \n",
    "        # [3] Find the dimension that is the smallest between the height and the width and assign it to the crop_drim variable.\n",
    "        crop_dim = min(height, width)\n",
    "        \n",
    "        # [4] Crop the centre of the image based on the crop_dim dimension for both the height and width.\n",
    "        crop_img = image[(height-crop_dim)//2:(height+crop_dim)//2, (width-crop_dim)//2:(width+crop_dim)//2]\n",
    "        \n",
    "        # [5] Resize the image to 48 x 48 and divide it with 255.0 to normalise it to floating point format.\n",
    "        image = cv2.resize(crop_img,(48,48))\n",
    "        image = np.float32(image)\n",
    "        image[:] = [x/255.0 for x in image]\n",
    "        return (image,label)\n",
    "    else:\n",
    "        # Error loading image\n",
    "        return (None, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataGenerator(img_addrs, img_labels, batch_size, num_classes):\n",
    "    while 1:\n",
    "        # Ensure randomisation per epoch\n",
    "        addrs_labels = list(zip(img_addrs,img_labels))\n",
    "        random.shuffle(addrs_labels)\n",
    "        img_addrs, img_labels = zip(*addrs_labels)\n",
    "        \n",
    "        X = []\n",
    "        Y = []\n",
    "        for i in range(len(img_addrs)):\n",
    "            # [1] Call the load_images function and \n",
    "            tpl = load_image(img_addrs[i])\n",
    "            #     append the image in X.\n",
    "            X.append(tpl[0])\n",
    "            # [2] Create a one-hot encoding with np.eye and append the one-hot vector to Y.\n",
    "            Y.append(np.eye(num_classes)[tpl[1]])\n",
    "            # [3] Commpare the count and batch_size (hint: modulo operation) and if so:\n",
    "            if len(X) % batch_size == 0 or (i+1) == len(img_addrs):\n",
    "                # Reshape X to fit input for model\n",
    "                lx = len(X)\n",
    "                X = np.asarray(X)\n",
    "                X = X.reshape(lx,2304)\n",
    "                #   - Use yield to return X,Y as numpy arrays with types 'float32' and 'uint8' respectively  \n",
    "                yield (np.float32(X),np.uint8(Y))\n",
    "                #   - delete X,Y\n",
    "                del X, Y\n",
    "                #   - set X,Y to []\n",
    "                X , Y = [],[]\n",
    "                #   - use python garbage collector\n",
    "                gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = paths_list_from_directory('./JPEGImages')\n",
    "\n",
    "# Use train test split\n",
    "X_train = []\n",
    "Y_train = []\n",
    "errs = []\n",
    "\n",
    "for p in range(len(paths[0])):\n",
    "    tpl = load_image(paths[0][p])\n",
    "    if tpl[1] != -1:\n",
    "        X_train.append(tpl[0])\n",
    "        Y_train.append(np.eye(nb_classes)[np.uint8(tpl[1])])\n",
    "    else:\n",
    "        errs.append(p)\n",
    "        \n",
    "X_val = []\n",
    "Y_val = []\n",
    "\n",
    "for p in range(len(paths[1])):\n",
    "    tpl = load_image(paths[1][p])\n",
    "    if(tpl[1] != -1):\n",
    "        X_val.append(tpl[0])\n",
    "        Y_val.append(np.eye(nb_classes)[np.uint8(tpl[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = len(X_train)\n",
    "lv = len(X_val)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "Y_train = np.asarray(Y_train)\n",
    "X_val = np.asarray(X_val)\n",
    "Y_val = np.asarray(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be changed to the right size\n",
    "inputs = Input(shape=(2304,))\n",
    "\n",
    "x = inputs\n",
    "x = Conv2D(filters=32, kernel_size=(3, 3), name='cnn_lab_conv1')(x)\n",
    "x = BatchNormalization(axis=bn_axis)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# Add MaxPool here\n",
    "\n",
    "# Second block\n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), name='cnn_lab_conv2')(x)\n",
    "x = BatchNormalization(axis=bn_axis)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# Add MaxPool here\n",
    "\n",
    "# Third block\n",
    "x = Conv2D(filters=128, kernel_size=(3, 3), name='cnn_lab_conv3')(x)\n",
    "x = BatchNormalization(axis=bn_axis)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# x = ShakeShake()(x)\n",
    "\n",
    "x = Flatten()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "model = Model(input=inputs, output=predictions)\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "\n",
    "# Populate training set with image paths\n",
    "for p in range(len(paths[0])):\n",
    "    flag = 0\n",
    "    for i in errs[0]:\n",
    "        if (p==i):\n",
    "            flag = 1\n",
    "    if flag == 0:\n",
    "        X_train.append(paths[0][p])\n",
    "\n",
    "# Calculate step sizes for both sets\n",
    "stepSizeTrain = math.ceil(len(X_train)/batch_size)\n",
    "stepSizeVal = math.ceil(lv/batch_size)\n",
    "\n",
    "#Convert labels to uint8\n",
    "Y_train = np.uint8(Y_train)\n",
    "Y_val = np.uint8(Y_val)\n",
    "\n",
    "# Define generators\n",
    "train_gen = DataGenerator(X_train, Y_train, batch_size = batch_size, num_classes = nb_classes)\n",
    "#val_gen = DataGenerator(X_train, Y_train, batch_size = batch_size, num_classes = nb_classes)\n",
    "\n",
    "# Run fit_generator\n",
    "history = model.fit_generator(generator = train_gen,\n",
    "                              epochs = nb_epoch,\n",
    "                              steps_per_epoch = stepSizeTrain)\n",
    "\n",
    "# Check score\n",
    "score = model.evaluate(X_val, Y_val, verbose=0)\n",
    "#history = model.fit_generator(\n",
    "    #DataGenerator(X_val, Y_val, batch_size=batch_size, num_classes=nb_classes), \n",
    "    #steps_per_epoch = stepSize, epochs=nb_epoch)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
