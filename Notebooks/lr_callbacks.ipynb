{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.callbacks import LearningRateScheduler, Callback\n",
    "import numpy as np\n",
    "from math import exp\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "--------------------------------------------------------------------------------------------------------\n",
    "                S T A R T   O F  C L A S S    I N T E R N A L S T A T E H I S T O R Y\n",
    "--------------------------------------------------------------------------------------------------------\n",
    "[About]\n",
    "\n",
    "    Class for returning the network's internal state parameter values per training phase epoch.\n",
    "    Records the loss history, accuracy, learning rate and number of iterations. This class is\n",
    "    to be used by other classes and functions when implementing custom LearningRateChedulers\n",
    "    and loss functions that are dependable on the previous values or the functions include\n",
    "    a adaptive methods.\n",
    "\n",
    "\n",
    "[Arguments]\n",
    "\n",
    "    None\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InternalStateHistory(Callback):\n",
    "\n",
    "    \"\"\"\n",
    "    --------------------------- F U N C T I O N   O N _ T R A I N _ B E G I N -------------------------\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "\n",
    "      # [1] initialise the logged losses to an empty list\n",
    "\n",
    "      # [2] initialise the logged learning rates to an empty list\n",
    "\n",
    "      # [4] initialise the logged accuraccy rates to an empty list\n",
    "\n",
    "      # [5] initialise the current iterration number to zero\n",
    "\n",
    "    \"\"\"\n",
    "    -------------------------------------- E N D   F U N C T I O N ------------------------------------\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    ----------------------------- F U N C T I O N   O N _ E P O C H _ E N D ---------------------------\n",
    "    \"\"\"\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "\n",
    "      # [1] append to the losses array the current loss by calling logs.get('loss')\n",
    "\n",
    "      # [2] append to the lr values array the current lr by calling from keras backend (imported as K) the `get_value` function with `self.model.optimizer.lr` as argument.\n",
    "\n",
    "      # [3] append the accuracy rate to the currosponding array similarly to how you obtained the loss.\n",
    "\n",
    "      # [4] get the iteration number from self.model.optimizer - as you did for the lr\n",
    "    \"\"\"\n",
    "    -------------------------------------- E N D   F U N C T I O N ------------------------------------\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "--------------------------------------------------------------------------------------------------------\n",
    "                E N D   O F  C L A S S    I N T E R N A L S T A T E H I S T O R Y\n",
    "--------------------------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "--------------------------------------------------------------------------------------------------------\n",
    "                S T A R T   O F  C L A S S    S T E P _  D E C A Y\n",
    "--------------------------------------------------------------------------------------------------------\n",
    "[About]\n",
    "\n",
    "    Class for decreasing the network's learning rate by a specific rate based on the upper and lower bound values given.\n",
    "\n",
    "\n",
    "[Arguments]\n",
    "\n",
    "    - min_lr: float defaulting to 1e-6, the minimum learning rate that the network can use (the lr in the final step).\n",
    "    - max_lr: float defaulting to .1, the maximum learning rate that the network can use (the lr in the first step).\n",
    "    - steps_per_epoch: integer, the number of steps (based on the batch size) that a full epoch will require.\n",
    "    - epochs: integer, the number of epochs that the trainig process will run for.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Step_decay(Callback):\n",
    "\n",
    "    \"\"\"\n",
    "    --------------------------- I N I T I A L I S A T I O N -------------------------\n",
    "    \"\"\"\n",
    "    def __init__(self, min_lr=1e-6, max_lr=0.1, num_steps=5, steps_per_epoch=None, epochs=None):\n",
    "\n",
    "      super().__init__()\n",
    "\n",
    "      # [1] Initialise the class variables:\n",
    "      # - min_lr\n",
    "      # - max_lr\n",
    "      # - total_iterations (steps_per_epoch * epochs)\n",
    "      # - iteration (your counter)\n",
    "      # - decrease which should be the (integer) value of the absolute difference between the max_lr - min_lr devided by the num_steps\n",
    "\n",
    "      temp = int(self.total_iterations // num_steps)\n",
    "\n",
    "      self.steps_pos = []\n",
    "\n",
    "      for pos in range(temp, int(self.total_iterations), temp):\n",
    "        self.steps_pos.append(pos)\n",
    "\n",
    "    \"\"\"\n",
    "    --------------------------- E N D  O F  I N I T I A L I S A T I O N -------------------------\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    --------------------------- F U N C T I O N  C A L C U L A T E _ N E W _ L R -------------------------\n",
    "    \"\"\"\n",
    "    def calculate_new_lr(self):\n",
    "\n",
    "      index = self.steps_pos.index(self.iteration) + 1\n",
    "\n",
    "      # [2] return the max_lr minus the decrease times your iteration index\n",
    "      return\n",
    "\n",
    "    \"\"\"\n",
    "    --------------------------- E N D  F U N C T I O N -------------------------\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    --------------------------- F U N C T I O N  O N _ T R A I N _ B E G I N -------------------------\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs=None):\n",
    "      logs = logs or {}\n",
    "      K.set_value(self.model.optimizer.lr, self.max_lr)\n",
    "\n",
    "    \"\"\"\n",
    "    --------------------------- E N D  F U N C T I O N -------------------------\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    --------------------------- F U N C T I O N  O N _ B A T C H _ E N D -------------------------\n",
    "    \"\"\"\n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "\n",
    "        logs = logs or {}\n",
    "\n",
    "        # [3] increase iteration counter by 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.iteration)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "\n",
    "        if (self.iteration in self.steps_pos):\n",
    "            K.set_value(self.model.optimizer.lr, self.calculate_new_lr())\n",
    "\n",
    "    \"\"\"\n",
    "    --------------------------- E N D  F U N C T I O N -------------------------\n",
    "    \"\"\"\n",
    "\"\"\"\n",
    "--------------------------------------------------------------------------------------------------------\n",
    "                E N D   O F  C L A S S    S T E P _ D E C A Y\n",
    "--------------------------------------------------------------------------------------------------------\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
